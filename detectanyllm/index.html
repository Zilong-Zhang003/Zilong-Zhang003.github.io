<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RAM++ - Research Paper</title>
    <link rel="icon" href="../images/MIRAGE_logo.png" type="image/png">
    <link rel="stylesheet" href="style.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Caveat:wght@700&family=Lato:wght@300;400;700&family=Poppins:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
    <!-- 主标题区域 -->
    <header class="hero">
        <div class="hero-content">
            <div class="title-animation">
                <h1 class="main-title">
                    <span class="title-word">RAM++</span>
                </h1>
                <h2 class="sub-title">
                    <u>R</u>obust Representation Learning via <br>  <u>A</u>daptive <u>M</u>ask for All-in-One Image Restoration
                </h2>
                
                <!-- 作者信息 -->
                <div class="authors-list" id="authors">
                    <a href="https://github.com/fjc2005" class="author-link" target="_blank">
                        Zilong Zhang
                    </a>
                    <span class="author-separator">,</span>
                    <a href="https://github.com/fjc2005" class="author-link" target="_blank">
                        Chujie Qin
                    </a>
                    <span class="author-separator">,</span>
                    <a href="https://mmcheng.net/clguo/" class="author-link" target="_blank">
                        Chunle Guo<sup>*</sup>
                    </a>
                    <span class="author-separator">,</span>
                    <a href="https://mmcheng.net/clguo/" class="author-link" target="_blank">
                        Ming-Ming Cheng<sup>*</sup>
                    </a>
                    <span class="author-separator">,</span>
                    <a href="https://li-chongyi.github.io/" class="author-link" target="_blank">
                        Chongyi Li<sup>†</sup>
                    </a>
                </div>
                
                <!-- 单位信息 -->
                <div class="affiliation">
                    <p data-en="VCIP, CS, Nankai University" data-zh="媒体计算实验室, 南开大学">VCIP, CS, Nankai University</p>
                </div>
                
                <div class="author-notes">
                    <p data-en="<sup>*</sup>Corresponding author &nbsp;&nbsp;&nbsp;&nbsp; <sup>†</sup>Project Lead" data-zh="<sup>*</sup>通讯作者 &nbsp;&nbsp;&nbsp;&nbsp; <sup>†</sup>项目负责人"><sup>*</sup>Corresponding Author &nbsp;&nbsp;&nbsp;&nbsp; <sup>†</sup>Project Lead</p>
                </div>
                
                <!-- <div class="subtitle">
                    <p data-en="Revolutionary depth estimation technology for any environmental conditions" data-zh="突破性的深度估计技术，适应任何环境条件">Revolutionary depth estimation technology for any environmental conditions</p>
                </div> -->
            </div>

            <!-- 交互按钮 -->
            <div class="cta-buttons">
                <button class="cta-btn primary" id="paper-btn">
                    <i class="fas fa-file-pdf"></i>
                    <span data-en="Paper" data-zh="阅读论文">Paper</span>
                </button>
                <button class="cta-btn arxiv" id="arxiv-btn">
                    <img src="image/arxiv.png" alt="arXiv" class="btn-icon">
                    <span data-en="arXiv" data-zh="arXiv">arXiv</span>
                </button>
                <button class="cta-btn secondary" id="code-btn">
                    <i class="fab fa-github"></i>
                    <span data-en="Code" data-zh="查看代码">Code</span>
                </button>
                <button class="cta-btn huggingface-model" id="model-btn">
                    <img src="image/huggingface_logo.svg" alt="Hugging Face" class="btn-icon">
                    <span data-en="Model" data-zh="模型">Model</span>
                </button>
            </div>
            
            <!-- Teaser 图片 -->
            <div class="teaser-container scroll-target">
                <img src="images/pipeline.jpg" alt="RAM++ - Teaser" class="teaser-image lazy-load" loading="lazy">
                <div class="image-placeholder"></div>
            </div>
            
            <div class="teaser-caption scroll-target delay-200" style="text-align: justify;">
                <p  data-en="An illustration of our overall pipeline. 
                    1) Pre-training the model with the Adaptive Semantic-Aware Mask image method tailored to low-level vision. We mask the degraded images’ semantically and texturally rich regions (\ie, high-information regions) at the pixel level with a 50% masking ratio and reconstruct the clean images.
                    2) Fine-tuning is performed to bridge the input integrity gap that arises when transitioning from masked inputs during pre-training to full images during inference. We assess the contribution of each network layer to addressing this gap using the proposed MAC, ranking them in descending order. The top k% of layers are then selected for fine-tuning on complete images.
                    3) The fine-tuning process is further assisted by a pre-trained vision foundation model, providing semantic consistency and degradation-invariant priors."
                    data-zh="整体流程示意图。  
                    1）首先使用自适应语义感知掩码（AdaSAM）方法对模型进行预训练，该方法专为低层视觉任务设计。我们在像素级别以50%的掩码比例遮盖退化图像中语义和纹理丰富的区域（即高信息区域），并对清晰图像进行重建。  
                    2）随后进行微调，以弥补在从预训练阶段的掩码输入过渡到推理阶段的完整图像时所产生的输入完整性差距。我们通过提出的 MAC 方法评估各网络层对这一差距的贡献，并按贡献从高到低排序，然后选择前k%的层在完整图像上进行微调。  
                    3）微调过程还借助于预训练的视觉基础模型DINOv2，从而提供语义一致性和退化不变的先验。
                    ">
                    Left: Our DetectAnyLLM achieves high efficiency, strong robustness, and impressive generalization through a three-step process: <i>sampling perturbation</i>, <i>calculating discrepancy</i>, and <i>reference clustering</i>. Right: Our MIRAGE benchmark emphasizes diversity across domains, tasks, evaluation scenarios, and source LLMs, enabling comprehensive and robust evaluation.
                </p>
            </div>
        </div>
        <nav class="navbar">
            <div class="nav-container">
                <div class="nav-logo">
                    <i class="fas fa-fingerprint"></i>
                    <span class="logo-animated-text">DetectAnyLLM</span>
                </div>
                <div class="nav-menu">
                    <a href="#abstract" class="nav-link" data-en="Abstract" data-zh="摘要">Abstract</a>
                    <a href="#method" class="nav-link" data-en="Method" data-zh="方法">Method</a>
                    <a href="#benchmark" class="nav-link" data-en="Benchmark" data-zh="基准">Benchmark</a>
                    <a href="#comparison" class="nav-link" data-en="Comparison" data-zh="对比">Comparison</a>
                    <!-- <a href="#data" class="nav-link" data-en="Data" data-zh="数据">Data</a> -->
                    <!-- <a href="#authors" class="nav-link" data-en="Authors" data-zh="作者">Authors</a> -->
                    <!-- <a href="#results" class="nav-link" data-en="Results" data-zh="结果">Results</a> -->
                    <a href="#code" class="nav-link" data-en="Download" data-zh="下载">Download</a>
                    <!-- <a href="#contact" class="nav-link" data-en="Contact" data-zh="联系">Contact</a> -->
                    <!-- <a href="#license" class="nav-link" data-en="License" data-zh="许可证">License</a> -->
                    <a href="#citation" class="nav-link" data-en="Citation" data-zh="引用">Citation</a>
                    <div class="language-switcher">
                        <button class="lang-btn active" data-lang="en">EN</button>
                        <span class="lang-separator">|</span>
                        <button class="lang-btn" data-lang="zh">中文</button>
                    </div>
                </div>
            </div>
        </nav>
        
        <!-- 滚动指示器 -->
        <div class="scroll-indicator">
            <div class="scroll-arrow">
                <i class="fas fa-chevron-down"></i>
            </div>
        </div>
    </header>

    <!-- 摘要部分 -->
    <section class="abstract-section" id="abstract">
        <div class="container scroll-target">
            <div class="section-header">
                <h2 class="section-title" data-en="Abstract" data-zh="摘要">Abstract</h2>
                <div class="section-divider"></div>
            </div>
            
            <!-- 详细摘要文本 -->
            <div class="abstract-text-container">
                <div class="abstract-paragraph">
                    <p data-en="The rapid advancement of large language models (LLMs) has blurred the boundary between human-written and machine-generated text, drawing urgent attention to the task of machine-generated text detection (MGTD). However, existing approaches struggle in complex real-world scenarios: zero-shot detectors rely heavily on scoring model's output distribution while training-based detectors are often constrained by overfitting to the training data, limiting generalization." 
                       data-zh="大型语言模型 (LLM) 的快速发展模糊了人类书写文本和机器生成文本之间的界限，使得机器生成文本检测 (MGTD) 任务备受关注。然而，现有方法在复杂的现实场景中表现不佳：零样本检测器严重依赖于评分模型的输出分布，而基于训练的检测器往往受制于对训练数据的过拟合，从而限制了泛化能力。">
                       The rapid advancement of large language models (LLMs) has blurred the boundary between human-written and machine-generated text, drawing urgent attention to the task of machine-generated text detection (MGTD). However, existing approaches struggle in complex real-world scenarios: zero-shot detectors rely heavily on scoring model's output distribution while training-based detectors are often constrained by overfitting to the training data, limiting generalization.
                    </p>
                    
                    <p data-en="We found that the performance bottleneck of training-based detectors stems from the misalignment between training objective and task needs, i.e., optimizing for token distribution rather than the MGTD task itself. To address this issue, we propose <b>Direct Discrepancy Learning (DDL)</b>, a novel optimization strategy that directly optimize the scoring model with task-oriented knowledge. DDL enables the scoring model to better capture the core semantics of the detection task, thereby enhancing both robustness and generalization. Built upon this approach, we introduce <b>DetectAnyLLM</b>, a unified detection framework that achieves state-of-the-art MGTD performance across diverse LLMs." 
                       data-zh="我们发现，基于训练的检测器的性能瓶颈源于训练目标与任务需求之间的不一致，即针对 token 分布进行优化，而不是针对 MGTD 任务本身。为了解决这个问题，我们提出了<b>直接差异学习 (DDL)</b>，这是一种新颖的优化策略，它利用面向任务的知识直接优化评分模型。DDL使评分模型能够更好地捕捉检测任务的核心语义，从而增强鲁棒性和泛化能力。基于此方法，我们推出了<b>DetectAnyLLM</b>，这是一个统一的检测框架，可在不同的LLM上实现最先进的MGTD性能。">
                       We found that the performance bottleneck of training-based detectors stems from the misalignment between training objective and task needs, i.e., optimizing for token distribution rather than the MGTD task itself. To address this issue, we propose <b>Direct Discrepancy Learning (DDL)</b>, a novel optimization strategy that directly optimize the scoring model with task-oriented knowledge. DDL enables the scoring model to better capture the core semantics of the detection task, thereby enhancing both robustness and generalization. Built upon this approach, we introduce <b>DetectAnyLLM</b>, a unified detection framework that achieves state-of-the-art MGTD performance across diverse LLMs.
                    </p>
                    
                    <p data-en="To ensure a robust and reliable evaluation, we construct <b>MIRAGE</b>, the most diverse multi-task MGTD benchmark. MIRAGE samples human-written texts from 10 corpora across 5 domains, which are then regenerated or revised using 17 cutting-edge LLMs, covering a wide spectrum of commercial models and textual styles. Extensive experiments on MIRAGE reveal the limitations of existing methods in complex environment. In contrast, DetectAnyLLM consistently outperforms them, achieving over a 70% performance improvement under the same training data and base scoring model, and thus underscores the effectiveness of our DDL. " 
                       data-zh="为了确保评估的稳健性和可靠性，我们构建了<b>MIRAGE</b>，这是迄今为止最具多样性的多任务MGTD基准测试集。MIRAGE 从 5 个领域的 10 个语料库中采样人工编写的文本，然后使用 17 个尖端的 LLM 对这些文本进行再生或修改，涵盖了广泛的商业模型和文本风格。在 MIRAGE 上进行的大量实验揭示了现有方法在复杂环境中的局限性。相比之下，DetectAnyLLM 的表现始终优于它们，在相同的训练数据和基本评分模型下实现了超过 70% 的性能提升，从而凸显了我们 DDL 的有效性。">
                       To ensure a robust and reliable evaluation, we construct <b>MIRAGE</b>, the most diverse multi-task MGTD benchmark. MIRAGE samples human-written texts from 10 corpora across 5 domains, which are then regenerated or revised using 17 cutting-edge LLMs, covering a wide spectrum of commercial models and textual styles. Extensive experiments on MIRAGE reveal the limitations of existing methods in complex environment. In contrast, DetectAnyLLM consistently outperforms them, achieving over a 70% performance improvement under the same training data and base scoring model, and thus underscores the effectiveness of our DDL. 
                    </p>
                </div>
            </div>
            
            <!-- 特性摘要卡片
            <div class="abstract-content">
                <div class="abstract-card">
                    <div class="abstract-icon">
                        <i class="fas fa-lightbulb"></i>
                    </div>
                    <div class="abstract-text">
                        <h3 data-en="Innovation Breakthrough" data-zh="创新突破">Innovation Breakthrough</h3>
                        <p data-en="This research proposes a revolutionary depth estimation method that maintains high-precision depth perception capabilities under various complex environmental conditions." data-zh="本研究提出了一种革命性的深度估计方法，能够在各种复杂环境条件下保持高精度的深度感知能力。">This research proposes a revolutionary depth estimation method that maintains high-precision depth perception capabilities under various complex environmental conditions.</p>
                    </div>
                </div>
                
                <div class="abstract-card">
                    <div class="abstract-icon">
                        <i class="fas fa-cog"></i>
                    </div>
                    <div class="abstract-text">
                        <h3 data-en="Technical Advantages" data-zh="技术优势">Technical Advantages</h3>
                        <p data-en="Through advanced neural network architectures and adaptive algorithms, robust handling of factors such as lighting changes, weather conditions, and object materials is achieved." data-zh="通过先进的神经网络架构和自适应算法，实现了对光照变化、天气条件、物体材质等因素的robust处理。">Through advanced neural network architectures and adaptive algorithms, robust handling of factors such as lighting changes, weather conditions, and object materials is achieved.</p>
                    </div>
                </div>
                
                <div class="abstract-card">
                    <div class="abstract-icon">
                        <i class="fas fa-chart-line"></i>
                    </div>
                    <div class="abstract-text">
                        <h3 data-en="Performance Results" data-zh="性能表现">Performance Results</h3>
                        <p data-en="Significant performance improvements have been achieved on multiple benchmark datasets, providing strong technical support for computer vision and robotics fields." data-zh="在多个基准数据集上取得了显著的性能提升，为计算机视觉和机器人领域提供了强有力的技术支撑。">Significant performance improvements have been achieved on multiple benchmark datasets, providing strong technical support for computer vision and robotics fields.</p>
                    </div>
                </div>
            </div> -->
        </div>
    </section>

    <!-- Method 部分 -->
    <section class="method-section" id="method">
        <div class="container scroll-target">
            <div class="section-header">
                <h2 class="section-title" data-en="Method" data-zh="方法">Method</h2>
                <div class="section-divider"></div>
            </div>
            
            <div class="method-image-container">
                <img src="image/ddl_small.png" alt="Direct Discrepancy Learning" class="method-image lazy-load" loading="lazy">
                <div class="image-placeholder"></div>
            </div>
            
            <div class="method-caption">
                <p data-en="While prior methods use optimization techniques like Direct Preference Optimization (DPO), they include a KL-regularization term that forces the detection model to retain its original language modeling abilities. We argue this is counter-productive, as it shifts the training objective away from learning to be an effective detector. <br><br> To address this, we propose <b>Direct Discrepancy Learning (DDL)</b>. By removing the redundant KL-regularization, we allow the scoring model to focus solely on learning task-oriented knowledge for detection. Our optimization goal is to directly maximize the discrepancy for machine-generated text (MGT) and minimize it for human-written text (HWT). <br><br> The DDL optimization objective is formulated as: <br> \[\min_\theta \mathbb{E}_{x_m, x_h \sim \mathcal{D}}(\Vert d_c(x_h, f_\theta, f_\theta)\Vert_1 + \Vert \gamma - d_c(x_m, f_\theta, f_\theta)\Vert_1).\] <br> This equation trains the model \(f_\theta\) to produce a low discrepancy score \(d_c\) (near 0) for HWT (\(x_h\)) and a high score (near \(\gamma\)) for MGT (\(x_m\)). DDL enables the scoring model to directly learn the difference between MGT and HWT, significantly boosting robustness and generalization. Finally, a <i>Reference Clustering</i> step is used to classify texts based on their scores."
                   data-zh="先前的方法采用直接偏好优化（DPO）等技术，但其中包含的KL正则化项会迫使检测模型保留其原始的语言建模能力。我们认为这会产生负面影响，因为它使训练目标偏离了学习成为一个有效检测器的方向。<br><br>为了解决这个问题，我们提出了<b>直接差异学习（DDL）</b>。通过移除冗余的KL正则化，我们让评分模型专注于学习面向检测任务的知识。我们的优化目标是直接最大化机器生成文本（MGT）的差异度，同时最小化人类编写文本（HWT）的差异度。<br><br>DDL的优化目标公式为：<br>\[\min_\theta \mathbb{E}_{x_m, x_h \sim \mathcal{D}}(\Vert d_c(x_h, f_\theta, f_\theta)\Vert_1 + \Vert \gamma - d_c(x_m, f_\theta, f_\theta)\Vert_1).\]<br>该方程训练模型\(f_\theta\)为HWT（\(x_h\)）生成较低的差异度分数（接近0），为MGT（\(x_m\)）生成较高的分数（接近\(\gamma\)）。DDL使评分模型能够直接学习MGT和HWT之间的区别，显著提升了模型的鲁棒性和泛化能力。最后，我们使用<i>参考聚类</i>步骤根据文本的差异度分数进行分类。">
                   While prior methods use optimization techniques like Direct Preference Optimization (DPO), they include a KL-regularization term that forces the detection model to retain its original language modeling abilities. We argue this is counter-productive, as it shifts the training objective away from learning to be an effective detector. <br><br> To address this, we propose <b>Direct Discrepancy Learning (DDL)</b>. By removing the redundant KL-regularization, we allow the scoring model to focus solely on learning task-oriented knowledge for detection. Our optimization goal is to directly maximize the discrepancy for machine-generated text (MGT) and minimize it for human-written text (HWT). <br><br> The DDL optimization objective is formulated as: <br> \[\min_\theta \mathbb{E}_{x_m, x_h \sim \mathcal{D}}(\Vert d_c(x_h, f_\theta, f_\theta)\Vert_1 + \Vert \gamma - d_c(x_m, f_\theta, f_\theta)\Vert_1).\] <br> This equation trains the model \(f_\theta\) to produce a low discrepancy score \(d_c\) (near 0) for HWT (\(x_h\)) and a high score (near \(\gamma\)) for MGT (\(x_m\)). DDL enables the scoring model to directly learn the difference between MGT and HWT, significantly boosting robustness and generalization. Finally, a <i>Reference Clustering</i> step is used to classify texts based on their scores.
                </p>
            </div>
        </div>
    </section>

    <!-- Benchmark 部分 -->
    <section class="benchmark-section" id="benchmark">
        <div class="container scroll-target">
            <div class="section-header">
                <h2 class="section-title" data-en="Benchmark" data-zh="基准">Benchmark</h2>
                <div class="section-divider"></div>
            </div>
            
            <div class="benchmark-image-container">
                <img src="image/workflow_small.png" alt="MIRAGE Benchmark Workflow" class="benchmark-image lazy-load" loading="lazy">
                <div class="image-placeholder"></div>
            </div>
            
            <div class="benchmark-caption">
                <p data-en="To address the limitations of existing benchmarks, which often lack diversity in domains, source LLMs, and tasks, we introduce <b>MIRAGE</b> (Multi-domain Inclusive Realistic Assessment for machine Generated text dEtection). MIRAGE is the most comprehensive multi-task MGTD evaluation framework to date, incorporating text across diverse domains generated or revised by 17 state-of-the-art LLMs (13 proprietary, 4 open-source). This rigorous process, involving multi-domain sampling, inclusive tasks, realistic scenarios, and style diversification, ensures MIRAGE provides a robust and realistic benchmark for evaluating MGT detectors, advancing the development of more generalizable and practical solutions." 
                   data-zh="为解决现有基准在领域、源LLM和任务多样性方面的局限性，我们推出了<b>MIRAGE</b>（面向机器生成文本检测的多领域包容性现实评估）基准。MIRAGE是目前最全面的多任务MGTD评估框架，涵盖了由17个先进LLM（13个专有模型，4个开源模型）在不同领域生成或修订的文本。通过多领域采样、包容性任务、现实场景和风格多样化等严谨流程，MIRAGE为评估MGT检测器提供了鲁棒且真实的基准，推动了更具泛化性和实用性的解决方案的发展。">
                    To address the limitations of existing benchmarks, which often lack diversity in domains, source LLMs, and tasks, we introduce <b>MIRAGE</b> (Multi-domain Inclusive Realistic Assessment for machine Generated text dEtection). MIRAGE is the most comprehensive multi-task MGTD evaluation framework to date, incorporating text across diverse domains generated or revised by 17 state-of-the-art LLMs (13 proprietary, 4 open-source). This rigorous process, involving multi-domain sampling, inclusive tasks, realistic scenarios, and style diversification, ensures MIRAGE provides a robust and realistic benchmark for evaluating MGT detectors, advancing the development of more generalizable and practical solutions.
                </p>
            </div>
        </div>
    </section>

    <!-- Data Coverage 部分 -->
    <section class="data-coverage-section" id="comparison">
        <div class="container scroll-target">
            <div class="section-header">
                <h2 class="section-title" data-en="Comparison" data-zh="对比">Comparison</h2>
                <div class="section-divider"></div>
            </div>
            <style>
                .best {
                    color: blue;
                    font-weight: bold;
                }
                .second {
                    color: rgb(3, 229, 229);
                    font-weight: bold;
                }
                .ood {
                color: red; /* OOD */
                font-weight: bold;
                }
            </style>
           <!-- Quantitative Comparison Table -->
            <h3 style="text-align:center;margin-bottom:1rem;" 
            data-en="Quantitative comparison on three challenging image restoration tasks" 
            data-zh="三个具有挑战性的图像复原任务定量对比">
            Quantitative comparison on three challenging image restoration tasks
            </h3>

            <div class="data-table-container">
            <div class="table-wrapper">
            <table class="data-table">
            <thead>
                <tr>
                <th rowspan="2" data-en="Method" data-zh="方法">Method</th>
                <th rowspan="2" data-en="SOTS (Dehaze)" data-zh="去雾 SOTS">SOTS</th>
                <th rowspan="2" data-en="Rain100L (Derain)" data-zh="去雨 Rain100L">Rain100L</th>
                <th colspan="3" data-en="BSD68 (Denoise)" data-zh="去噪 BSD68">BSD68</th>
                <th rowspan="2" data-en="Average" data-zh="平均">Average</th>
                </tr>
                <tr>
                <th>&sigma;=15</th>
                <th>&sigma;=25</th>
                <th>&sigma;=50</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                <td>Restormer</td>
                <td>27.78/0.958</td>
                <td>33.72/0.865</td>
                <td>33.72/0.865</td>
                <td>30.67/0.865</td>
                <td>27.63/0.792</td>
                <td>30.75/0.901</td>
                </tr>
                <tr>
                <td>MPRNet</td>
                <td>28.00/0.958</td>
                <td>33.86/0.958</td>
                <td>33.27/0.920</td>
                <td>30.76/0.871</td>
                <td>27.29/0.761</td>
                <td>30.63/0.894</td>
                </tr>
                <tr>
                <td>NAFNet</td>
                <td>24.11/0.960</td>
                <td>33.64/0.956</td>
                <td>33.18/0.918</td>
                <td>30.47/0.865</td>
                <td>27.12/0.754</td>
                <td>29.67/0.844</td>
                </tr>
                <tr>
                <td>DL</td>
                <td>26.92/0.931</td>
                <td>32.62/0.931</td>
                <td>33.05/0.914</td>
                <td>30.41/0.861</td>
                <td>26.90/0.740</td>
                <td>29.98/0.875</td>
                </tr>
                <tr>
                <td>AirNet</td>
                <td>27.94/0.962</td>
                <td>34.90/0.967</td>
                <td>33.92/<span class="second">0.933</span></td>
                <td>31.26/0.888</td>
                <td>28.00/0.797</td>
                <td>31.20/0.910</td>
                </tr>
                <tr>
                <td>PromptIR</td>
                <td>30.58/0.974</td>
                <td>36.37/0.972</td>
                <td>33.98/<span class="second">0.933</span></td>
                <td>31.31/0.888</td>
                <td>28.06/0.799</td>
                <td>32.06/0.913</td>
                </tr>
                <tr>
                <td>InstructIR-3D</td>
                <td>30.22/0.959</td>
                <td>37.98/0.978</td>
                <td><span class="second">34.15</span>/<span class="second">0.933</span></td>
                <td><span class="second">31.52</span>/<span class="second">0.890</span></td>
                <td><span class="best">28.30</span>/<span class="best">0.804</span></td>
                <td>32.43/0.913</td>
                </tr>
                <tr>
                <td>Art<sub>AirNet</sub></td>
                <td>30.56/0.977</td>
                <td>37.74/0.981</td>
                <td>34.02/<span class="best">0.934</span></td>
                <td>31.37/<span class="second">0.890</span></td>
                <td>28.12/<span class="second">0.802</span></td>
                <td>32.36/<span class="second">0.917</span></td>
                </tr>
                <tr>
                <td>Art<sub>PromptIR</sub></td>
                <td>30.83/<span class="second">0.979</span></td>
                <td>37.94/0.982</td>
                <td>34.06/<span class="best">0.934</span></td>
                <td>31.42/<span class="best">0.891</span></td>
                <td>28.14/0.801</td>
                <td>32.49/<span class="second">0.917</span></td>
                </tr>
                <tr>
                <td>GridFormer</td>
                <td>30.37/0.970</td>
                <td>37.15/0.972</td>
                <td>33.93/0.931</td>
                <td>31.37/0.887</td>
                <td>28.11/0.801</td>
                <td>32.19/0.912</td>
                </tr>
                <tr>
                <td>RAM<sub>Restormer</sub></td>
                <td>30.26/0.975</td>
                <td>37.89/0.982</td>
                <td><span class="second">34.15</span>/0.932</td>
                <td>31.51/0.888</td>
                <td>28.24/0.800</td>
                <td>32.41/0.915</td>
                </tr>
                <tr>
                <td>MoCE-IR</td>
                <td><span class="second">31.12</span>/<span class="second">0.979</span></td>
                <td><span class="second">38.72</span>/<span class="second">0.984</span></td>
                <td>34.13/0.932</td>
                <td>31.47/0.888</td>
                <td>28.20/0.800</td>
                <td><span class="second">32.73</span>/<span class="second">0.917</span></td>
                </tr>
                <tr class="our-method-row">
                <td>RAM++<sub>30%</sub>(ours)</td>
                <td>31.10/0.978</td>
                <td>37.78/0.981</td>
                <td>34.09/0.932</td>
                <td>31.49/0.889</td>
                <td>28.25/0.801</td>
                <td>32.54/0.916</td>
                </tr>
                <tr class="our-method-row">
                <td>RAM++<sub>100%</sub>(ours)</td>
                <td><span class="best">31.90</span>/<span class="best">0.980</span></td>
                <td><span class="best">38.87</span>/<span class="best">0.985</span></td>
                <td><span class="best">34.18</span>/<span class="second">0.933</span></td>
                <td><span class="best">31.55</span>/0.889</td>
                <td><span class="second">28.29</span>/<span class="second">0.802</span></td>
                <td><span class="best">32.96</span>/<span class="best">0.918</span></td>
                </tr>
            </tbody>
            </table>
            </div>

            <div class="table-caption">
                <p data-en="Red indicates the best results, and Blue indicates the second-best results." 
                data-zh="红色表示最佳结果，蓝色表示次优结果。">
                Red indicates the best results, and blue indicates the second-best results.
                </p>
                </div>
            </div>

            <h3 style="text-align:center;margin-bottom:1rem;"
                data-en="Quantitative comparison on seven challenging image restoration tasks"
                data-zh="七个具有挑战性的图像复原任务上的定量对比">
                Quantitative comparison on seven challenging image restoration tasks
            </h3>

            <div class="data-table-container">
            <div class="table-wrapper">
                <table class="data-table">
                <thead>
                    <tr>
                    <th rowspan="2">Method</th>
                    <th>SOTS</th>
                    <th>Rain13k-Test</th>
                    <th>BSD68</th>
                    <th>GoPro</th>
                    <th>LOL</th>
                    <th>LSDIR-Blur</th>
                    <th>LSDIR-JPEG</th>
                    <th>Average</th>
                    </tr>
                    <tr>
                    <th>PSNR/SSIM</th>
                    <th>PSNR/SSIM</th>
                    <th>PSNR/SSIM</th>
                    <th>PSNR/SSIM</th>
                    <th>PSNR/SSIM</th>
                    <th>PSNR/SSIM</th>
                    <th>PSNR/SSIM</th>
                    <th>PSNR/SSIM</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                    <td>Restormer</td>
                    <td>22.89/0.9172</td>
                    <td>27.05/0.8469</td>
                    <td><span class="best">30.95</span>/<span class="best">0.8657</span></td>
                    <td>27.46/0.8497</td>
                    <td>23.65/0.8458</td>
                    <td>19.60/0.3658</td>
                    <td><span class="best">30.46</span>/<span class="best">0.9141</span></td>
                    <td>26.01/0.8007</td>
                    </tr>
                    <tr>
                    <td>MPRNet</td>
                    <td>25.23/0.9463</td>
                    <td>25.36/0.8068</td>
                    <td>29.83/0.8317</td>
                    <td>25.90/0.7949</td>
                    <td>22.29/0.8170</td>
                    <td>25.68/0.8281</td>
                    <td>28.96/0.8865</td>
                    <td>26.18/0.8445</td>
                    </tr>
                    <tr>
                    <td>NAFNet</td>
                    <td>25.74/0.9445</td>
                    <td>24.65/0.7877</td>
                    <td>30.37/0.8540</td>
                    <td>25.53/0.7909</td>
                    <td>21.50/0.8104</td>
                    <td>29.08/0.9130</td>
                    <td>29.09/0.8955</td>
                    <td>26.57/0.8566</td>
                    </tr>
                    <tr>
                    <td>DL</td>
                    <td>21.16/0.9042</td>
                    <td>19.56/0.6508</td>
                    <td>16.15/0.5861</td>
                    <td>17.63/0.5862</td>
                    <td>19.26/0.7777</td>
                    <td>17.98/0.6121</td>
                    <td>19.55/0.6965</td>
                    <td>18.75/0.6877</td>
                    </tr>
                    <tr>
                    <td>TAPE</td>
                    <td>25.14/0.9319</td>
                    <td>23.66/0.7818</td>
                    <td>30.11/0.8354</td>
                    <td>25.97/0.7962</td>
                    <td>18.95/0.7632</td>
                    <td>24.26/0.7654</td>
                    <td>29.28/0.8965</td>
                    <td>25.34/0.8243</td>
                    </tr>
                    <tr>
                    <td>AirNet</td>
                    <td>21.66/0.8366</td>
                    <td>20.21/0.6402</td>
                    <td>27.99/0.7250</td>
                    <td>23.36/0.7503</td>
                    <td>16.65/0.6708</td>
                    <td>23.84/0.7358</td>
                    <td>24.36/0.8020</td>
                    <td>22.58/0.7372</td>
                    </tr>
                    <tr>
                    <td>SwinIR</td>
                    <td>27.29/0.9622</td>
                    <td>25.32/0.8258</td>
                    <td>30.65/0.8540</td>
                    <td>26.61/0.8125</td>
                    <td>18.66/0.8048</td>
                    <td>27.82/0.8839</td>
                    <td>30.13/0.9071</td>
                    <td>26.64/0.8643</td>
                    </tr>
                    <tr>
                    <td>PromptIR</td>
                    <td>28.70/0.9659</td>
                    <td>27.46/0.8585</td>
                    <td>30.84/0.8625</td>
                    <td>27.71/0.8565</td>
                    <td>21.19/0.8356</td>
                    <td><span class="second">31.01</span>/<span class="second">0.9385</span></td>
                    <td>30.30/0.9117</td>
                    <td>28.17/0.8899</td>
                    </tr>
                    <tr>
                        <td>MoCE-IR</td>
                        <td>30.16/0.9719</td>
                        <td>27.86/0.8608</td>
                        <td>30.57/0.8556</td>
                        <td>27.70/0.8506</td>
                        <td>24.00/0.8446</td>
                        <td>27.96/0.8837</td>
                        <td>29.88/0.9049</td>
                        <td>28.30/0.8817</td>
                    </tr>
                    <tr>
                        <td>HOGFormer</td>
                        <td>29.21/0.9685</td>
                        <td>27.09/0.8415</td>
                        <td>30.61/0.8551</td>
                        <td>27.64/0.8477</td>
                        <td>21.38/0.8273</td>
                        <td><span class="best">32.02</span>/<span class="best">0.9480</span></td>
                        <td>30.20/0.9092</td>
                        <td>28.31/0.8853</td>
                    </tr>
                    <tr>
                        <td>RAM<sub>SwinIR</sub></td>
                        <td>28.47/0.9689</td>
                        <td>26.31/0.8486</td>
                        <td>30.83/0.8611</td>
                        <td>26.89/0.8200</td>
                        <td>21.62/0.8291</td>
                        <td>26.66/0.8514</td>
                        <td>30.22/0.9096</td>
                        <td>27.28/0.8698</td>
                    </tr>
                    <tr>
                        <td>RAM<sub>PromptIR</sub></td>
                        <td>29.64/0.9695</td>
                        <td>28.47/0.8751</td>
                        <td>30.86/0.8624</td>
                        <td><span class="second">28.02</span>/<span class="second">0.8592</span></td>
                        <td>24.46/0.8581</td>
                        <td>29.57/0.9179</td>
                        <td>30.33/0.9119</td>
                        <td>28.76/<span class="second">0.8935</span></td>
                    </tr>
                    <tr>
                        <td>RAM<sub>Restormer</sub></td>
                        <td>29.97/0.9721</td>
                        <td>27.97/0.8666</td>
                        <td><span class="second">30.88</span>/0.8631</td>
                        <td>27.83/0.8582</td>
                        <td>24.15/<span class="second">0.8613</span></td>
                        <td>29.50/0.9153</td>
                        <td>30.37/0.9127</td>
                        <td>28.67/0.8928</td>
                    </tr>          
                    <tr class="our-method-row">
                    <td><b>RAM++<sub>30%</sub>(ours)</b></td>
                    <td><span class="second">31.67</span>/<span class="second">0.9760</span></td>
                    <td><span class="second">28.52</span>/<span class="second">0.8782</span></td>
                    <td>30.82/<span class="second">0.8654</span></td>
                    <td>27.61/0.8489</td>
                    <td><span class="second">24.86</span>/0.8545</td>
                    <td>28.45/0.8926</td>
                    <td>30.19/0.9107</td>
                    <td><span class="second">28.88</span>/0.8895</td>
                    </tr>
                    <tr class="our-method-row">
                    <td class="our-method-row"><b>RAM++<sub>100%</sub>(ours)</b></td>
                    <td><span class="best">31.91</span>/<span class="best">0.9782</span></td>
                    <td><span class="best">29.53</span>/<span class="best">0.8919</span></td>
                    <td><span class="best">30.95</span>/0.8652</td>
                    <td><span class="best">28.19</span>/<span class="best">0.8621</span></td>
                    <td><span class="best">25.23</span>/<span class="best">0.8619</span></td>
                    <td>29.96/0.9219</td>
                    <td><span class="second">30.43</span>/<span class="second">0.9139</span></td>
                    <td><span class="best">29.46</span>/<span class="best">0.8993</span></td>
                    </tr>
                </tbody>
                </table>
            </div>

            <div class="table-caption">
                <p data-en="Red indicates the best results, and Blue indicates the second-best results." 
                data-zh="红色表示最佳结果，蓝色表示次优结果。">
                Red indicates the best results, and blue indicates the second-best results.
                </p>
                </div>
            </div>

            <h3 style="text-align:center;margin-bottom:1rem;" 
                data-en="Quantitative comparison of PSNR for models trained under Setting 2 (7-task) on the CDD-11 dataset" 
                data-zh="在 CDD-11 数据集上，Setting 2 (7 任务) 下训练模型的 PSNR 定量对比">
                Quantitative comparison of PSNR for models trained under Setting 2 (7-task) on the CDD-11 dataset
            </h3>
            <div class="data-table-container">
                <div class="table-wrapper">
                  <table class="data-table">
                    <thead>
                      <tr>
                        <th rowspan="2">Method</th>
                        <th colspan="4">CDD11-Single</th>
                        <th colspan="5">CDD11-Double</th>
                        <th colspan="2">CDD11-Triple</th>
                        <th rowspan="2">Average</th>
                      </tr>
                      <tr>
                        <th>Low (L)</th>
                        <th>Haze (H)</th>
                        <th>Rain (R)</th>
                        <th><span class="ood">Snow (S)</span></th>
                        <th>L+H</th>
                        <th>L+R</th>
                        <th>L+<span class="ood">S</span></th>
                        <th>H+R</th>
                        <th>H+<span class="ood">S</span></th>
                        <th>L+H+R</th>
                        <th>L+H+<span class="ood">S</span></th>
                      </tr>
                    </thead>
                    <tbody>
                        <tr>
                          <td>AirNet</td>
                          <td>12.04</td><td>16.84</td><td>22.35</td><td>22.64</td>
                          <td>14.93</td><td>14.77</td><td>13.56</td><td>15.41</td><td>15.44</td>
                          <td>15.30</td><td>14.65</td><td>16.17</td>
                        </tr>
                        <tr>
                          <td>Restormer</td>
                          <td>12.15</td><td>16.17</td><td>25.06</td><td>23.66</td>
                          <td>15.01</td><td>14.92</td><td>13.68</td><td>15.33</td><td>14.93</td>
                          <td>15.33</td><td>14.67</td><td>16.45</td>
                        </tr>
                        <tr>
                          <td>SwinIR</td>
                          <td><span class="second">12.24</span></td><td>16.97</td><td>22.19</td><td>23.44</td>
                          <td><span class="second">15.05</span></td><td><span class="best">15.00</span></td><td><span class="best">13.76</span></td><td>16.25</td><td>15.69</td>
                          <td>15.36</td><td><span class="second">14.70</span></td><td>16.42</td>
                        </tr>
                        <tr>
                          <td>PromptIR</td>
                          <td>12.14</td><td>16.53</td><td>26.27</td><td>23.65</td>
                          <td>15.00</td><td>14.64</td><td>13.68</td><td>16.09</td><td>15.17</td>
                          <td>15.38</td><td>14.68</td><td>16.66</td>
                        </tr>
                        <tr>
                          <td>HOGFormer</td>
                          <td>12.12</td><td>15.71</td><td>22.92</td><td>22.18</td>
                          <td>14.94</td><td>14.91</td><td>13.69</td><td>16.87</td><td>14.69</td>
                          <td>15.36</td><td>14.65</td><td>16.19</td>
                        </tr>
                        <tr>
                          <td>MoCE-IR</td>
                          <td>12.14</td><td>15.70</td><td>24.92</td><td>20.22</td>
                          <td>14.99</td><td><span class="second">14.94</span></td><td><span class="best">13.76</span></td><td>15.32</td><td>13.60</td>
                          <td>15.36</td><td>14.58</td><td>15.96</td>
                        </tr>
                        <tr>
                          <td>RAM<sub>PromptIR</sub></td>
                          <td>12.13</td><td>17.03</td><td><span class="best">28.21</span></td><td><span class="best">23.76</span></td>
                          <td>14.97</td><td>14.46</td><td>13.68</td><td>16.11</td><td>15.49</td>
                          <td>15.35</td><td>14.65</td><td>16.90</td>
                        </tr>
                        <tr>
                          <td>RAM<sub>Restormer</sub></td>
                          <td>12.15</td><td><span class="second">18.11</span></td><td>26.82</td><td><span class="second">23.73</span></td>
                          <td>14.98</td><td>14.67</td><td>13.69</td><td><span class="second">17.11</span></td><td><span class="second">16.05</span></td>
                          <td><span class="best">15.41</span></td><td>14.65</td><td><span class="second">17.03</span></td>
                        </tr>
                        <tr>
                          <td>RAM++ 100%</td>
                          <td><span class="best">12.26</span></td><td><span class="best">19.07</span></td><td><span class="second">27.37</span></td><td>22.78</td>
                          <td><span class="best">15.11</span></td><td>14.88</td><td><span class="second">13.71</span></td><td><span class="best">17.19</span></td><td><span class="best">16.68</span></td>
                          <td><span class="second">15.40</span></td><td><span class="best">14.71</span></td><td><span class="best">17.20</span></td>
                        </tr>
                      </tbody>
                  </table>
                </div>
              
                <div class="table-caption" style="text-align:center; margin-top:0.5rem;">
                  <p data-en="Blue indicates the best results, Teal indicates the second-best, Red indicates OOD degradation types." 
                     data-zh="蓝色表示最佳结果，青色表示次优结果，红色表示 OOD 退化类型。">
                     Blue indicates the best results, Teal indicates the second-best, Red indicates OOD degradation types.
                  </p>
                </div>
              </div>


            <!-- Performance Comparison Table -->
            <h3 style="text-align:center;margin:2rem 0 1rem 0;" data-en="Performance on MIRAGE" data-zh="MIRAGE性能对比">Performance on MIRAGE</h3>
            <div class="data-table-container">
                <div class="table-wrapper" style="overflow-x:auto;">
                    <!-- DIG Table -->
                    <table class="data-table performance-table">
                        <caption>MIRAGE-DIG</caption>
                        <thead>
                            <tr>
                                <th rowspan="2">Methods</th>
                                <th colspan="4">Generate</th>
                                <th colspan="4">Polish</th>
                                <th colspan="4">Rewrite</th>
                            </tr>
                            <tr>
                                <th>AUROC</th><th>Acc.</th><th>MCC</th><th>TPR@5%</th>
                                <th>AUROC</th><th>Acc.</th><th>MCC</th><th>TPR@5%</th>
                                <th>AUROC</th><th>Acc.</th><th>MCC</th><th>TPR@5%</th>
                            </tr>
                        </thead>
                        <tbody>
                            <!-- Only include representative rows to keep table readable -->
                            <tr>
                                <td>Fast-DetectGPT</td>
                                <td>0.7768</td><td>0.7234</td><td>0.4628</td><td>0.4310</td>
                                <td>0.5720</td><td>0.5570</td><td>0.1293</td><td>0.1189</td>
                                <td>0.5455</td><td>0.5432</td><td>0.1015</td><td>0.1025</td>
                            </tr>
                            <tr>
                                <td>ImBD</td>
                                <td>0.8597</td><td>0.7738</td><td>0.5497</td><td>0.4065</td>
                                <td>0.7888</td><td>0.7148</td><td>0.4300</td><td>0.2730</td>
                                <td>0.7825</td><td>0.7068</td><td>0.4139</td><td>0.2933</td>
                            </tr>
                            <tr class="our-method-row">
                                <td>DetectAnyLLM (ours)</td>
                                <td>0.9525</td><td>0.8988</td><td>0.7975</td><td>0.7770</td>
                                <td>0.9297</td><td>0.8732</td><td>0.7487</td><td>0.7756</td>
                                <td>0.9234</td><td>0.8705</td><td>0.7447</td><td>0.7778</td>
                            </tr>
                        </tbody>
                    </table>
                    <!-- SIG Table -->
                    <table class="data-table performance-table" style="margin-top:2rem;">
                        <caption>MIRAGE-SIG</caption>
                        <thead>
                            <tr>
                                <th rowspan="2">Methods</th>
                                <th colspan="4">Generate</th>
                                <th colspan="4">Polish</th>
                                <th colspan="4">Rewrite</th>
                            </tr>
                            <tr>
                                <th>AUROC</th><th>Acc.</th><th>MCC</th><th>TPR@5%</th>
                                <th>AUROC</th><th>Acc.</th><th>MCC</th><th>TPR@5%</th>
                                <th>AUROC</th><th>Acc.</th><th>MCC</th><th>TPR@5%</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Fast-DetectGPT</td>
                                <td>0.7706</td><td>0.7193</td><td>0.2078</td><td>0.4200</td>
                                <td>0.5727</td><td>0.5619</td><td>0.0607</td><td>0.1238</td>
                                <td>0.5480</td><td>0.5495</td><td>0.0525</td><td>0.1097</td>
                            </tr>
                            <tr>
                                <td>ImBD</td>
                                <td>0.8612</td><td>0.7791</td><td>0.5599</td><td>0.4183</td>
                                <td>0.7951</td><td>0.7199</td><td>0.4451</td><td>0.3036</td>
                                <td>0.7694</td><td>0.6920</td><td>0.3936</td><td>0.2868</td>
                            </tr>
                            <tr class="our-method-row">
                                <td>DetectAnyLLM (ours)</td>
                                <td>0.9526</td><td>0.9059</td><td>0.8119</td><td>0.7722</td>
                                <td>0.9316</td><td>0.8740</td><td>0.7483</td><td>0.7779</td>
                                <td>0.9158</td><td>0.8643</td><td>0.7320</td><td>0.7574</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
                <div class="table-caption">
                    <p data-en="DetectAnyLLM vastly outperforms prior methods on MIRAGE under both DIG and SIG settings across all tasks." data-zh="DetectAnyLLM在MIRAGE的DIG和SIG两种评估下显著领先于所有对比方法。">DetectAnyLLM vastly outperforms prior methods on MIRAGE under both DIG and SIG settings across all tasks.</p>
                </div>
            </div>
        </div>
    </section>

    <!-- 代码和资源部分 -->
    <section class="code-section" id="code">
        <div class="container scroll-target">
            <div class="section-header">
                <h2 class="section-title" data-en="Open Source Resources" data-zh="开源资源">Open Source Resources</h2>
                <div class="section-divider"></div>
            </div>
            <div class="code-resources">
                <div class="resource-card">
                    <div class="resource-icon">
                        <i class="fab fa-github"></i>
                    </div>
                    <div class="resource-content">
                        <h3 data-en="GitHub Repository" data-zh="GitHub 代码库">GitHub Repository</h3>
                        <p data-en="Complete implementation code, pre-trained models and usage examples" data-zh="完整的实现代码、预训练模型和使用示例">Complete implementation code, pre-trained models and usage examples</p>
                        <button class="resource-btn">
                            <span data-en="Visit GitHub" data-zh="访问 GitHub">Visit GitHub</span>
                            <i class="fas fa-external-link-alt"></i>
                        </button>
                    </div>
                </div>
                
                <div class="resource-card">
                    <div class="resource-icon">
                        <i class="fas fa-database"></i>
                    </div>
                    <div class="resource-content">
                        <h3 data-en="Datasets" data-zh="数据集">Datasets</h3>
                        <p data-en="Download links for training and evaluation datasets" data-zh="训练和评估使用的数据集下载链接">Download links for training and evaluation datasets</p>
                        <button class="resource-btn">
                            <span data-en="Download Data" data-zh="下载数据">Download Data</span>
                            <i class="fas fa-download"></i>
                        </button>
                    </div>
                </div>
                
                <div class="resource-card" style="text-align: center;">
                    <div class="resource-icon">
                        <i class="fas fa-brain"></i>
                    </div>
                    <div class="resource-content">
                        <h3 data-en="Pre-trained Models" data-zh="预训练模型">Pre-trained Models</h3>
                        <p data-en="DetectAnyLLM model checkpoint and backbone" data-zh="DetectAnyLLM模型检查点和骨干网络" style="text-align: center;">DetectAnyLLM model checkpoint and backbone</p>
                        <a href="https://huggingface.co/fjc2005/DetectAnyLLM" target="_blank" class="resource-btn">
                            <span data-en="Download Models" data-zh="下载模型">Download Models</span>
                            <i class="fas fa-download"></i>
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Contact部分 -->
    <section class="contact-section" id="contact">
        <div class="container scroll-target">
            <div class="section-header">
                <h2 class="section-title" data-en="Contact" data-zh="联系我们">Contact</h2>
                <div class="section-divider"></div>
            </div>
            <div class="contact-content">
                <p class="contact-text" style="font-size: 1.5rem;" data-en="Feel free to contact us at:" 
                   data-zh="欢迎联系我们：">
                    Feel free to contact us at:
                </p>
                <p class="contact-text" style="font-size: 1.5rem;">
                    guochunle@nankai.edu.cn
                </p>
                <p class="contact-text" style="font-size: 1.5rem;">
                    fjc@mail.nankai.edu.cn
                </p>
                <p class="contact-text" style="font-size: 1.5rem;" data-en="For commercial licensing, please contact:" 
                   data-zh="商业许可请联系：">
                    For commercial licensing, please contact:
                </p>
                <p class="contact-text" style="font-size: 1.5rem;">
                    lichongyi@nankai.edu.cn
                </p>
            </div>
        </div>
    </section>

    <!-- License部分 -->
    <section class="license-section" id="license">
        <div class="container scroll-target">
            <div class="section-header">
                <h2 class="section-title" data-en="License" data-zh="许可证">License</h2>
                <div class="section-divider"></div>
            </div>
            <div class="license-content">
                <div class="license-container">
                    <div class="license-text" style="width: 100%; text-align: justify;">
                        <h3 data-en="Pi-Lab License 1.0" data-zh="Pi-Lab 许可证 1.0">Pi-Lab License 1.0</h3>
                        <p data-en="Copyright 2025 Pi-Lab" data-zh="版权所有 2025 Pi-Lab">Copyright 2025 Pi-Lab</p>
                        <div class="license-actions">
                            <a href="https://github.com/fjc2005/DetectAnyLLM/blob/main/LICENSE.txt" target="_blank" class="license-btn">
                                <i class="fas fa-external-link-alt"></i>
                                <span data-en="View License" data-zh="查看许可证">View License</span>
                            </a>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Citation部分 -->
    <section class="citation-section" id="citation">
        <div class="container scroll-target">
            <div class="section-header">
                <h2 class="section-title" data-en="Citation" data-zh="引用信息">Citation</h2>
                <div class="section-divider"></div>
            </div>
            <div class="citation-content">
                <div class="bibtex-container">
                    <div class="bibtex-header">
                        <span class="bibtex-label">BibTeX</span>
                        <button class="copy-btn" id="copy-bibtex">
                            <i class="fas fa-copy"></i>
                            <span data-en="Copy" data-zh="复制">Copy</span>
                        </button>
                    </div>
                    <pre class="bibtex-code" id="bibtex-text">
@inproceedings{fu2025detectanyllm,
    title        = {DetectAnyLLM: Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models},
    author       = {Fu, Jiachen and Guo, Chun-Le and Li, Chongyi},
    year         = 2025,
    booktitle    = {the 33rd ACM International Conference on Multimedia},
    address      = {Dublin, Ireland},
    organization = {ACM}
}
                    </pre>
                </div>
            </div>
        </div>
    </section>

    <!-- 回到顶部按钮 -->
    <button class="back-to-top" id="back-to-top" aria-label="Back to top">
        <i class="fas fa-chevron-up"></i>
    </button>

    <!-- 页脚 -->
    <footer class="footer">
        <div class="container">
            <div class="footer-content">
                <div class="footer-text">
                    <p data-en="&copy; 2024 DetectAnyLLM. All rights reserved." data-zh="&copy; 2024 DetectAnyLLM. 保留所有权利。">&copy; 2024 DetectAnyLLM. All rights reserved.</p>
                </div>
                <!-- <div class="footer-links">
                    <a href="#" class="footer-link" data-en="Contact Us" data-zh="联系我们">Contact Us</a>
                    <a href="#" class="footer-link" data-en="Citation" data-zh="引用信息">Citation</a>
                    <a href="#" class="footer-link" data-en="Related Work" data-zh="相关工作">Related Work</a>
                </div> -->
            </div>
        </div>
    </footer>



    <script src="script.js"></script>
</body>
</html> 